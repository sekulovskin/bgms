<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Bayesian analysis of networks of binary and/or ordinal variables using the bgm function</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
margin-bottom: 0em;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Bayesian analysis of networks of binary
and/or ordinal variables using the bgm function</h1>



<style>
body {
text-align: justify}
</style>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>This example demonstrates how to use the <code>bgm</code> function
for the Bayesian analysis of a networks of binary and/or ordinal data
(i.e., a Markov Random Field (MRF) model for mixed binary and ordinal
data). To learn more about the MRF model, check out <span class="citation">Marsman et al. (<a href="#ref-MarsmanHaslbeck_2023_ordinal">in press</a>)</span>, and to
learn more about the Bayesian analysis of network models, check out
<span class="citation">Huth et al. (<a href="#ref-HuthEtAl_2023">2023</a>)</span> or <span class="citation">Sekulovski et al. (<a href="#ref-SekulovskiEtAl_2023">2024</a>)</span>.</p>
<p>We’ll examine real data on PTSD symptoms from 362 Chinese adults who
survived the Wenchuan earthquake but tragically lost a child <span class="citation">(<a href="#ref-McNallyEtAl_2015">McNally et al.,
2015</a>)</span>. The data comes from a 17-question survey where
participants rated how much each symptom bothered them in the past month
on a scale from “not at all” to “extremely.”</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(bgms)</span></code></pre></div>
</div>
<div id="example-bayesian-model-averaging" class="section level1">
<h1>Example – Bayesian Model Averaging</h1>
<p>A comprehensive Bayesian analysis of the data considers both the
network structure and its corresponding parameters. As numerous
structures could underlie our network, we employ simulation-based
methods to investigate the posterior distribution of network structures
and parameters <span class="citation">(<a href="#ref-MarsmanHaslbeck_2023_ordinal">Marsman et al., in
press</a>)</span>. The <code>bgm</code> function performs this task,
iteratively simulating values from the posterior distribution of network
structures and parameters.</p>
<div id="usage" class="section level2">
<h2>Usage</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">bgm</span>(x,</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>    <span class="at">variable_type =</span> <span class="st">&quot;ordinal&quot;</span>,</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>    reference_category,</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    <span class="at">iter =</span> <span class="fl">1e4</span>,</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>    <span class="at">burnin =</span> <span class="fl">1e3</span>,</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    <span class="at">interaction_scale =</span> <span class="fl">2.5</span>,</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>    <span class="at">threshold_alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>    <span class="at">threshold_beta =</span> <span class="fl">0.5</span>,</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>    <span class="at">edge_selection =</span> <span class="cn">TRUE</span>,</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>    <span class="at">edge_prior =</span> <span class="fu">c</span>(<span class="st">&quot;Bernoulli&quot;</span>, <span class="st">&quot;Beta-Bernoulli&quot;</span>, <span class="st">&quot;Stochastic-Block&quot;</span>),</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>    <span class="at">inclusion_probability =</span> <span class="fl">0.5</span>,</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>    <span class="at">beta_bernoulli_alpha =</span> <span class="dv">1</span>,</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>    <span class="at">beta_bernoulli_beta =</span> <span class="dv">1</span>,</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>    <span class="at">dirichlet_alpha =</span> <span class="dv">1</span>,</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>    <span class="at">na.action =</span> <span class="fu">c</span>(<span class="st">&quot;listwise&quot;</span>, <span class="st">&quot;impute&quot;</span>),</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>    <span class="at">save =</span> <span class="cn">FALSE</span>,</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>    <span class="at">display_progress =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="arguments" class="section level2">
<h2>Arguments</h2>
<ul>
<li><p><code>x</code>: A data frame or matrix with <code>n</code> rows
and <code>p</code> columns, containing binary and ordinal variables for
<code>n</code> independent observations and <code>p</code> variables in
the network. Regular binary and ordinal variables are recoded as
non-negative integers (0, 1, …, m) if not already done. Unobserved
categories are collapsed into other categories after recoding (i.e., if
category 1 is unobserved, the data will be recoded from (0, 2) to (0,
1)). Blume-Capel ordinal variables are also coded as non-negative
integers if not already done. However, since ``distance’’ to the
reference category plays an important role in this model, unobserved
categories are not collapsed after recoding.</p></li>
<li><p><code>variable_type</code>: What kind of variables are there in
<code>x</code>? Can be a single character string specifying the variable
type of all <code>p</code> variables at once or a vector of character
strings of length <code>p</code> specifying the type for each variable
in <code>x</code> separately. Currently, bgm supports “ordinal” and
“blume-capel”. Binary variables are automatically treated as “ordinal”.
Defaults to <code>variable_type = &quot;ordinal&quot;</code>.</p></li>
<li><p><code>reference_category</code>: The reference category in the
Blume-Capel model. Should be an integer within the range of integer
scores observed for the “blume-capel” variable. Can be a single number
specifying the reference category for all Blume-Capel variables at once,
or a vector of length <code>p</code> where the <code>i</code>-th element
contains the reference category for variable <code>i</code> if it is
Blume-Capel, and bgm ignores its elements for other variable types. The
value of the reference category is also recoded when bgm recodes the
corresponding observations. Only required if there is at least one
variable of type “blume-capel”.</p></li>
<li><p><code>iter</code>: How many iterations should the Gibbs sampler
run? The default of <code>1e4</code> is for illustrative purposes. For
stable estimates, it is recommended to run the Gibbs sampler for at
least <code>1e5</code> iterations.</p></li>
<li><p><code>burnin</code>: The number of iterations of the Gibbs
sampler before its output is saved. Since it may take some time for the
Gibbs sampler to converge to the posterior distribution, it is
recommended not to set this number too low.</p></li>
<li><p><code>interaction_scale</code>: The scale of the Cauchy
distribution that is used as prior for the pairwise interaction
parameters. Defaults to <code>2.5</code>.</p></li>
<li><p><code>threshold_alpha, threshold_beta</code>: The shape
parameters of the beta-prime prior density for the threshold parameters.
Must be positive values. If the two values are equal, the prior density
is symmetric about zero. If <code>threshold_beta</code> is greater than
<code>threshold_alpha</code>, the distribution is skewed to the left,
and if <code>threshold_beta</code> is less than
<code>threshold_alpha</code>, it is skewed to the right. Smaller values
tend to lead to more diffuse prior distributions.</p></li>
<li><p><code>edge_selection</code>: Should the function perform Bayesian
edge selection on the edges of the MRF in addition to estimating its
parameters (<code>edge_selection = TRUE</code>), or should it just
estimate the parameters (<code>edge_selection = FALSE</code>)? The
default is <code>edge_selection = TRUE</code>.</p></li>
<li><p><code>edge_prior</code>: The prior distribution for the edges or
structure of the network. Two prior distributions are currently
implemented: The Bernoulli model <code>edge_prior = &quot;Bernoulli&quot;</code>
assumes that the probability that an edge between two variables is
included is equal to <code>inclusion_probability</code> and independent
of other edges or variables. When
<code>inclusion_probability = 0.5</code>, this implies that each network
structure receives the same prior weight. The Beta-Bernoulli model
<code>edge_prior = &quot;Beta-Bernoulli&quot;</code> assumes a beta prior for the
unknown inclusion probability with shape parameters
<code>beta_bernoulli_alpha</code> and <code>beta_bernoulli_beta</code>.
If <code>beta_bernoulli_alpha = 1</code> and
<code>beta_bernoulli_beta = 1</code>, this means that networks with the
same complexity (number of edges) receive the same prior weight.
Defaults to `edge_prior = “Bernoulli”’. The Stochastic Block model
assumes that nodes can be organized into blocks or clusters. In
principle, the assignment of nodes to such clusters is unknown, and the
model as implemented here considers all possible options (i.e.,
specifies a Dirichlet process on the node to block allocation <span class="citation">Geng et al. (<a href="#ref-GengEtAl_2019">2019</a>)</span>). This model is advantageous
when nodes are expected to fall into distinct clusters. The inclusion
probabilities for the edges are defined at the level of the clusters,
with a beta prior for the unknown inclusion probability with shape
parameters and . The default is .</p></li>
<li><p><code>inclusion_probability</code>: The prior edge inclusion
probability for the Bernoulli model. Can be a single probability, or a
matrix of <code>p</code> rows and <code>p</code> columns specifying an
inclusion probability for each edge pair. Defaults to
<code>inclusion_probability = 0.5</code>.</p></li>
<li><p><code>beta_bernoulli_alpha, beta_bernoulli_beta</code>: The two
shape parameters of the Beta prior density for the Bernoulli inclusion
probability. Must be positive numbers. Defaults to
<code>beta_bernoulli_alpha = 1</code> and
<code>beta_bernoulli_beta = 1</code>.</p></li>
<li><p><code>dirichlet_alpha</code>: The shape of the Dirichlet prior on
the node-to-block allocation parameters for the Stochastic Block model.
Must be a positive number. Defaults to
<code>dirichlet_alpha = 1</code></p></li>
<li><p><code>na.action</code>: How do you want the function to handle
missing data? If <code>na.action = &quot;listwise&quot;</code>, listwise deletion
is used. If <code>na.action = &quot;impute&quot;</code>, missing data are imputed
iteratively during the MCMC procedure. Since imputation of missing data
can have a negative impact on the convergence speed of the MCMC
procedure, it is recommended to run the MCMC for more iterations. Also,
since the numerical routines that search for the mode of the posterior
do not have an imputation option, the bgm function will automatically
switch to <code>interaction_prior = &quot;Cauchy&quot;</code> and
<code>adaptive = TRUE</code>.</p></li>
<li><p><code>save</code>: Should the function collect and return all
samples from the Gibbs sampler (<code>save = TRUE</code>)? Or should it
only return the (model-averaged) posterior means
(<code>save = FALSE</code>)? Defaults to FALSE.</p></li>
<li><p><code>display_progress</code>: Should the function show a
progress bar (<code>display_progress = TRUE</code>)? Or not
(<code>display_progress = FALSE</code>)? Defaults to TRUE.</p></li>
</ul>
</div>
<div id="output" class="section level2">
<h2>Output</h2>
<p>If <code>save = FALSE</code> (the default), the result is a list
containing the following matrices:</p>
<ul>
<li><code>indicator</code>: A matrix with <code>p</code> rows and
<code>p</code> columns, containing posterior inclusion probabilities of
individual edges.</li>
<li><code>interactions</code>: A matrix with <code>p</code> rows and
<code>p</code> columns, containing model-averaged posterior means of the
pairwise associations.</li>
<li><code>thresholds</code>: A matrix with <code>p</code> rows and
<code>max(m)</code> columns, containing model-averaged category
thresholds.</li>
</ul>
<p>If <code>save = TRUE</code>, the result is a list containing:</p>
<ul>
<li><code>indicator</code>: A matrix with <code>iter</code> rows and
<code>p * (p - 1) / 2</code> columns, containing the edge inclusion
indicators from every iteration of the Gibbs sampler.</li>
<li><code>interactions</code>: A matrix with <code>iter</code> rows and
<code>p * (p - 1) / 2</code> columns, containing parameter states from
every iteration of the Gibbs sampler for the pairwise associations.</li>
<li><code>thresholds</code>: A matrix with <code>iter</code> rows and
<code>sum(m)</code> columns, containing parameter states from every
iteration of the Gibbs sampler for the category thresholds.</li>
</ul>
<p>Column averages of these matrices provide the model-averaged
posterior means.</p>
</div>
<div id="analysis" class="section level2">
<h2>Analysis</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>fit <span class="ot">&lt;-</span>  <span class="fu">bgm</span>(<span class="at">x =</span> Wenchuan)</span></code></pre></div>
<p>To save time, we ran the algorithm using the default number of
iterations, which is 10,000. However, this is probably not enough to
fully explore the posterior distribution of the network structures and
parameters. To obtain reliable and accurate estimates, we recommend
increasing the number of iterations to 100,000 or more.</p>
<p>The function employs a simulation method that averages over all
plausible network structures to estimate the posterior inclusion
probability, which represents the probability that a network containing
the edge in question generated the observed data. Let’s plot the
relation between interaction estimates and inclusion probabilities.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">5</span>, <span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> fit<span class="sc">$</span>interactions[<span class="fu">lower.tri</span>(fit<span class="sc">$</span>interactions)], </span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>     <span class="at">y =</span> fit<span class="sc">$</span>indicator[<span class="fu">lower.tri</span>(fit<span class="sc">$</span>indicator)], <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), </span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">bg =</span> <span class="st">&quot;gray&quot;</span>, <span class="at">cex =</span> <span class="fl">1.3</span>)</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;gray&quot;</span>)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">1</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;gray&quot;</span>)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> .<span class="dv">5</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;gray&quot;</span>)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;Posterior mean edge weight&quot;</span>, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">line =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">1.7</span>)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;Posterior inclusion probability&quot;</span>, <span class="at">side =</span> <span class="dv">2</span>, <span class="at">line =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">1.7</span>)</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>)</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">las =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>We see that estimated edge weights (interactions) near zero have low
inclusion probabilities, and that edge weights far from zero have high
inclusion probabilities. A zero inclusion probability corresponds to
<code>bgm</code> setting the edge weight to exactly zero.</p>
<div id="median-probability-network" class="section level3">
<h3>Median probability network</h3>
<p>Using the posterior inclusion probabilities, we can also identify the
median probability network. In this network, we include all edges with a
posterior inclusion probability greater than <code>0.5</code>. We can
create the median probability model as follows.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">library</span>(qgraph) <span class="co">#For plotting the estimated network</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>  </span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>posterior.inclusion <span class="ot">&lt;-</span> fit<span class="sc">$</span>indicator[<span class="fu">lower.tri</span>(fit<span class="sc">$</span>indicator)]</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>tmp <span class="ot">&lt;-</span> fit<span class="sc">$</span>interactions[<span class="fu">lower.tri</span>(fit<span class="sc">$</span>interactions)]</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>tmp[posterior.inclusion <span class="sc">&lt;</span> <span class="fl">0.5</span>] <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>  </span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>median.prob.model <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> <span class="fu">ncol</span>(Wenchuan), <span class="at">ncol =</span> <span class="fu">ncol</span>(Wenchuan))</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>median.prob.model[<span class="fu">lower.tri</span>(median.prob.model)] <span class="ot">&lt;-</span> tmp</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>median.prob.model <span class="ot">&lt;-</span> median.prob.model <span class="sc">+</span> <span class="fu">t</span>(median.prob.model)</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>  </span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="fu">rownames</span>(median.prob.model) <span class="ot">&lt;-</span> <span class="fu">colnames</span>(Wenchuan)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="fu">colnames</span>(median.prob.model) <span class="ot">&lt;-</span> <span class="fu">colnames</span>(Wenchuan)</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>  </span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="fu">qgraph</span>(median.prob.model, </span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>       <span class="at">theme =</span> <span class="st">&quot;TeamFortress&quot;</span>, </span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>       <span class="at">maximum =</span> .<span class="dv">5</span>,</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>       <span class="at">fade =</span> <span class="cn">FALSE</span>,</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>       <span class="at">color =</span> <span class="fu">c</span>(<span class="st">&quot;#f0ae0e&quot;</span>), <span class="at">vsize =</span> <span class="dv">10</span>, <span class="at">repulsion =</span> .<span class="dv">9</span>, </span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>       <span class="at">label.cex =</span> <span class="fl">1.1</span>, <span class="at">label.scale =</span> <span class="st">&quot;FALSE&quot;</span>, </span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>       <span class="at">labels =</span> <span class="fu">colnames</span>(Wenchuan))</span></code></pre></div>
</div>
<div id="inclusion-bayes-factors" class="section level3">
<h3>Inclusion Bayes factors</h3>
<p>One of the benefits of using a fully Bayesian approach is that it
allows us to calculate the inclusion Bayes factor <span class="citation">Huth et al. (<a href="#ref-HuthEtAl_2023">2023</a>)</span>. The inclusion Bayes factor
represents the relative evidence for including or excluding a connection
between a pair of nodes in the network. An inclusion Bayes factor of 10
suggests that the observed data is ten times more likely to have come
from a network that includes the relationship. Conversely, an inclusion
Bayes factor of 1/10 implies that the observed data is ten times more
likely to have come from a network that excludes the relationship. It’s
important to note that inclusion Bayes factors can also reveal limited
support for either hypothesis.</p>
<p>In the current version analysis, it is assumed that the prior
inclusion probabilities are equal to <code>0.5</code>. Users can change
this by either adapting <code>inclusion_probability</code> or to choose
<code>edge_prior = &quot;Beta-Bernoulli&quot;</code> and pick different values for
<code>beta_bernoulli_alpha</code> and <code>beta_bernoulli_beta</code>.
Since here the inclusion probability is <code>0.5</code>, the prior odds
for inclusion vs exclusion is one. To calculate the inclusion Bayes
factors, we can thus simply convert the estimated posterior inclusion
probabilities. For easier visualization, it is common to use the natural
logarithm of the Bayes factor when plotting.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Calculate the inclusion BFs</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>prior.odds <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>posterior.inclusion <span class="ot">=</span> fit<span class="sc">$</span>indicator[<span class="fu">lower.tri</span>(fit<span class="sc">$</span>indicator)]</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>posterior.odds <span class="ot">=</span> posterior.inclusion <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> posterior.inclusion)</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>log.bayesfactor <span class="ot">=</span> <span class="fu">log</span>(posterior.odds <span class="sc">/</span> prior.odds)</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co">#The next line is used to truncate the extreme values of the Bayes factor in the plot</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>log.bayesfactor[log.bayesfactor <span class="sc">&gt;</span> <span class="dv">5</span>] <span class="ot">=</span> <span class="dv">5</span></span></code></pre></div>
<p>Lets plot the relation between the estimated edge weights and the
inclusion Bayes factor.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">+</span> <span class="fl">0.1</span>)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="fu">plot</span>(fit<span class="sc">$</span>interactions[<span class="fu">lower.tri</span>(fit<span class="sc">$</span>interactions)], log.bayesfactor, <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">bg =</span> <span class="st">&quot;#bfbfbf&quot;</span>, </span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>    <span class="at">cex =</span> <span class="fl">1.3</span>, <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="fl">5.5</span>),</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>    <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">las =</span> <span class="dv">1</span>)</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">log</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">10</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;#bfbfbf&quot;</span>)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">log</span>(<span class="dv">10</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;#bfbfbf&quot;</span>)</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="dv">10</span>), <span class="at">labels =</span> <span class="st">&quot;Evidence for exclusion&quot;</span>, <span class="at">pos =</span> <span class="dv">1</span>,</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>    <span class="at">cex =</span> <span class="fl">1.7</span>)</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="fu">log</span>(<span class="dv">10</span>), <span class="at">labels =</span> <span class="st">&quot;Evidence for inclusion&quot;</span>, <span class="at">pos =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">1.7</span>)</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">labels =</span> <span class="st">&quot;Weak evidence&quot;</span>, <span class="at">cex =</span> <span class="fl">1.7</span>)</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;Log-inclusion Bayes factor&quot;</span>, <span class="at">side =</span> <span class="dv">2</span>, <span class="at">line =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">1.5</span>, <span class="at">las =</span> <span class="dv">0</span>)</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;Posterior mean edge weights &quot;</span>, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">line =</span> <span class="fl">3.7</span>, <span class="at">cex =</span> <span class="fl">1.5</span>, <span class="at">las =</span> <span class="dv">0</span>)</span></code></pre></div>
<p>In this example, we use a cut-off value of <code>10</code> for the
inclusion Bayes factors. Values greater than <code>10</code> suggest
evidence for edge inclusion, values less than <code>1/10</code> indicate
evidence for edge exclusion, and values between <code>1/10</code> and
<code>10</code> are considered to represent weak evidence.</p>
</div>
</div>
<div id="analysis-with-raw-output" class="section level2">
<h2>Analysis with raw output</h2>
<p>For most purposes, the default output from <code>bgm</code> is
sufficient, providing us with the posterior means of edge indicators and
parameters. However, in some cases, we may want to use the raw samples
from the joint posterior distribution. This could be to estimate the
posterior distribution of a specific parameter, assess how many network
structures fit the given data, or create Bayes factors for hypotheses
involving multiple edges. We can obtain the raw samples by setting
<code>save = TRUE</code>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>fit <span class="ot">&lt;-</span>  <span class="fu">bgm</span>(<span class="at">x =</span> Wenchuan, <span class="at">save =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<div id="posterior-density-of-edge-weight" class="section level3">
<h3>Posterior density of edge weight</h3>
<p>We can employ the following code to use the posterior samples for
plotting the posterior density of a single edge:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>den <span class="ot">=</span> <span class="fu">density</span>(fit<span class="sc">$</span>interactions[,<span class="dv">1</span>], <span class="at">bw =</span> <span class="st">&quot;SJ&quot;</span>)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>i <span class="ot">=</span> <span class="fu">which.min</span>(<span class="fu">abs</span>(den<span class="sc">$</span>x <span class="sc">-</span> <span class="fu">mean</span>(fit<span class="sc">$</span>interactions[,<span class="dv">1</span>])))[<span class="dv">1</span>]</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>x <span class="ot">=</span> den<span class="sc">$</span>x[i]</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>f <span class="ot">=</span> den<span class="sc">$</span>y[i]</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="fu">par</span>(<span class="at">cex.main =</span> <span class="fl">1.5</span>, <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">+</span> <span class="fl">0.1</span>, <span class="at">mgp =</span> <span class="fu">c</span>(<span class="fl">3.5</span>, <span class="dv">1</span>, <span class="dv">0</span>), <span class="at">cex.lab =</span> <span class="fl">1.5</span>, <span class="at">font.lab =</span> <span class="dv">2</span>, <span class="at">cex.axis =</span> <span class="fl">1.3</span>, <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="at">las =</span> <span class="dv">1</span>)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="fu">plot</span>(den, <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">xlab=</span><span class="st">&quot;&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">main =</span> <span class="st">&quot;&quot;</span>, <span class="at">frame.plot =</span> <span class="cn">FALSE</span>)</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>)</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="fu">par</span>(<span class="at">las =</span> <span class="dv">0</span>)</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a><span class="fu">mtext</span>(<span class="at">text =</span> <span class="st">&quot;Edge weight&quot;</span>, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">line =</span> <span class="fl">2.5</span>, <span class="at">cex =</span> <span class="fl">1.5</span>)</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a><span class="fu">mtext</span>(<span class="at">text =</span> <span class="st">&quot;Posterior density&quot;</span>, <span class="at">side =</span> <span class="dv">2</span>, <span class="at">line =</span> <span class="fl">2.5</span>, <span class="at">cex =</span> <span class="fl">1.5</span>)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a><span class="co"># Add a point to indicate the posterior mean</span></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a><span class="fu">points</span>(x, f, <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">bg =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">cex =</span> <span class="fl">1.7</span>)</span></code></pre></div>
<p>The posterior distribution of the edge weight is averaged across all
structures, which can lead to greater dispersion compared to estimating
it for a specific model. This is because it takes into account the
uncertainty of the network structures and the parameter estimates
associated with these structures.</p>
<p>Note that the estimate is not very smooth. This is because we only
used 10,000 samples to estimate the posterior distribution.</p>
</div>
</div>
<div id="the-posterior-distribution-of-structures" class="section level2">
<h2>The posterior distribution of structures</h2>
<p>We can also use the raw samples to count the number of unique
structures <code>bgm</code> encountered in 10,000 iterations.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>I <span class="ot">=</span> <span class="dv">2</span> <span class="sc">*</span> fit<span class="sc">$</span>indicator <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>S <span class="ot">=</span> <span class="fu">unique</span>(I)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="fu">nrow</span>(S)</span></code></pre></div>
<p>There are clearly many different network structures that could fit
the data. Let’s estimate their posterior probabilities.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>Ps <span class="ot">=</span> <span class="fu">vector</span>(<span class="at">length =</span> <span class="fu">nrow</span>(S))</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(S)) {</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>  s <span class="ot">=</span> S[r, ]</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>  tmp <span class="ot">=</span> I <span class="sc">%*%</span> s</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>  Ps[r] <span class="ot">=</span> <span class="fu">sum</span>(tmp <span class="sc">==</span> <span class="fu">ncol</span>(I))</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>}</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>Ps <span class="ot">=</span> Ps <span class="sc">/</span> <span class="fu">nrow</span>(I) <span class="sc">*</span> <span class="dv">100</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="fu">max</span>(Ps)</span></code></pre></div>
<p>The most plausible model accounts for less than <code>1</code>
percent of the posterior probability. In conclusion, we have significant
uncertainty about the network structure that generated the data.</p>
<p>In the analysis by <span class="citation">Marsman et al. (<a href="#ref-MarsmanHaslbeck_2023_ordinal">in press</a>)</span>, it is
demonstrated that even when there is uncertainty about the network
structure that generated the data, inclusion Bayes factors are highly
robust. They can help identify substructures of the network in which we
have strong confidence. However, to perform these analyses, we need to
run <code>bgm</code> for many more iterations. In their analysis, <span class="citation">Marsman et al. (<a href="#ref-MarsmanHaslbeck_2023_ordinal">in press</a>)</span> used
1,000,000 iterations. For further details, interested readers can refer
to their analysis script <a href="https://osf.io/qsj4w/files/osfstorage/6401be88bbc5e50b9bf81466">here</a>.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="unnumbered">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0" line-spacing="2">
<div id="ref-GengEtAl_2019" class="csl-entry">
Geng, J., Bhattacharya, A., &amp; Pati, D. (2019). Probabilistic
community detection with unknown number of communities. <em>Journal of
the American Statistical Association</em>, <em>114</em>, 893–905. <a href="https://doi.org/10.1080/01621459.2018.1458618">https://doi.org/10.1080/01621459.2018.1458618</a>
</div>
<div id="ref-HuthEtAl_2023" class="csl-entry">
Huth, K., de Ron, J., Goudriaan, A. E., Luigjes, K., Mohammadi, R., van
Holst, R. J., Wagenmakers, E.-J., &amp; Marsman, M. (2023). Bayesian
analysis of cross-sectional networks: <span>A</span> tutorial in
<span>R</span> and <span>JASP</span>. <em>Advances in
<span>M</span>ethods and <span>P</span>ractices in
<span>P</span>sychological <span>S</span>cience</em>. <a href="https://doi.org/10.1177/25152459231193334">https://doi.org/10.1177/25152459231193334</a>
</div>
<div id="ref-MarsmanHaslbeck_2023_ordinal" class="csl-entry">
Marsman, M., Bergh, D. van den, &amp; Haslbeck, J. M. B. (in press).
Bayesian analysis of the ordinal <span>M</span>arkov random field.
<em>Psychometrika</em>.
</div>
<div id="ref-McNallyEtAl_2015" class="csl-entry">
McNally, R. J., Robinaugh, D. J., Wu, G. W. Y., Wang, L., Deserno, M.
K., &amp; Borsboom, D. (2015). Mental disorders as causal systems:
<span>A</span> network approach to posttraumatic stress disorder.
<em>Clinical Psychological Science</em>, <em>5</em>, 836–849. <a href="https://doi.org/10.1177/2167702614553230">https://doi.org/10.1177/2167702614553230</a>
</div>
<div id="ref-SekulovskiEtAl_2023" class="csl-entry">
Sekulovski, N., Keetelaar, S., Huth, K. B. S., Wagenmakers, E.-J., van
Bork, R., van den Bergh, D., &amp; Marsman, M. (2024). Testing
conditional independence in psychometric networks: <span>A</span>n
analysis of three <span>B</span>ayesian methods. <em>Multivariate
Behavioral Research</em>, <em>59</em>, 913–933. <a href="https://doi.org/10.1080/00273171.2024.2345915">https://doi.org/10.1080/00273171.2024.2345915</a>
</div>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
